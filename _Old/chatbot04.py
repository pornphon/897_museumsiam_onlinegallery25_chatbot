import os
import streamlit as st
from dotenv import load_dotenv
import pymysql

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_core.tools import tool
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from pinecone import Pinecone
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate, SystemMessagePromptTemplate


# ‡πÇ‡∏´‡∏•‡∏î ENV
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
INDEX_NAME = os.getenv("PINECONE_INDEX")

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Pinecone
pc = Pinecone(api_key=PINECONE_API_KEY)

index_names = {
    "name_th": "antiquities-name-th-index",
    "material_tags": "antiquities-material-tags-index",
    "artistic_description_th": "antiquities-artistic-description-th-index",
    "place_tags": "antiquities-place-tags-index",
    "historical_description_th": "antiquities-description-th-index"
}

# ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞ index
index_name = pc.Index(index_names["name_th"])
index_material = pc.Index(index_names["material_tags"])
index_artistic = pc.Index(index_names["artistic_description_th"])
index_place = pc.Index(index_names["place_tags"])
index_history = pc.Index(index_names["historical_description_th"])

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Embeddings ‡πÅ‡∏•‡∏∞ LLM
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
llm = ChatOpenAI(model="gpt-4o")

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° VectorStores
#vectorstore_name = PineconeVectorStore(index=index_name, embedding=embeddings, namespace="name_namespace")
vectorstore_name = PineconeVectorStore(index=index_name, embedding=embeddings, namespace="")
vectorstore_material = PineconeVectorStore(index=index_material, embedding=embeddings, namespace="")
vectorstore_artistic = PineconeVectorStore(index=index_artistic, embedding=embeddings, namespace="")
vectorstore_place = PineconeVectorStore(index=index_place, embedding=embeddings, namespace="")
vectorstore_history = PineconeVectorStore(index=index_history, embedding=embeddings, namespace="")


def get_antiquity_by_id_from_db(antiquity_id: str) -> dict:
    conn = pymysql.connect(
        host='localhost',
        user='root',
        password='',
        database='vm_siam',
        charset='utf8mb4',
        cursorclass=pymysql.cursors.DictCursor
    )
    try:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM antiquities WHERE id = %s", (antiquity_id,))
            return cursor.fetchone()
    finally:
        conn.close()




# ‡∏™‡∏£‡πâ‡∏≤‡∏á Tools
@tool
def search_by_name(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ ‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô (name_th) ‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    #retriever = vectorstore_name.as_retriever(search_type="mmr",search_kwargs={"k": 3})
    retriever = vectorstore_name.as_retriever(search_type="similarity", search_kwargs={"k": 3})

    #print("search by name ")
    docs = retriever.invoke(query)

    if not docs:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    
    ids = [doc.metadata.get("id", "") for doc in docs if doc.metadata.get("id")]
    print(f"üîç ‡∏û‡∏ö ID ‡∏à‡∏≤‡∏Å Pinecone: {', '.join(ids)}")
    
    results = []

    for aid in ids:
        data = get_antiquity_by_id_from_db(aid)
        if data:
            # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏≤‡∏á field ‡∏Å‡πá‡πÑ‡∏î‡πâ
            summary = f"üÜî {data['id']}\nüìõ ‡∏ä‡∏∑‡πà‡∏≠: {data.get('name_th', '-')}\nüìú ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {data.get('artistic_description_th', '-')}\nüìç ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö: {data.get('place_found', '-')}"
            print("result: "+summary)
            results.append(summary)

    return "\n\n".join(results) if results else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MySQL"

@tool
def search_by_material(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏™‡∏î‡∏∏ (material_tags) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_material.as_retriever(search_kwargs={"k": 3})
    docs = retriever.invoke(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

@tool
def search_by_artistic_description(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏®‡∏¥‡∏•‡∏õ‡∏∞ (artistic_description_th) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_artistic.as_retriever(search_kwargs={"k": 3})
    docs = retriever.invoke(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

@tool
def search_by_place_tags(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏•‡∏¥‡∏ï (place_tags) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_place.as_retriever(search_kwargs={"k": 3})
    docs = retriever.invoke(query)

    return ",".join(doc.metadata.get("id", "") for doc in docs)

@tool
def search_by_description(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (historical_background_description_th) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_history.as_retriever(search_kwargs={"k": 3})
    docs = retriever.invoke(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

@tool #‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏õ‡πÄ‡∏≠‡∏≤‡∏à‡∏≤‡∏Å DB
def general_information(query: str) -> str:
    """‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö museumsiam ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ, ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà, ‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡∏¥‡∏î"""
    retriever = vectorstore_history.as_retriever(search_kwargs={"k": 3})
    docs = retriever.invoke(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

tools = [
    search_by_name,
    search_by_material,
    search_by_artistic_description,
    search_by_place_tags,
    search_by_description,
    general_information
]

# Prompt Template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡∏∏‡∏õ
agent_prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(
        "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    ),
    HumanMessagePromptTemplate.from_template("{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])


# ‡∏™‡∏£‡πâ‡∏≤‡∏á Agent ‡∏û‡∏£‡πâ‡∏≠‡∏° Prompt
agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)







# result = search_by_name.invoke("‡∏à‡∏≤‡∏ô‡∏•‡∏≤‡∏¢‡∏õ‡∏•‡∏≤")
# print(result)

st.set_page_config(page_title="Museum Chatbot", page_icon="üè∫")
st.title("Museum Siam - RAG + Agent")

question = st.text_input("üì• ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:")
# Streamlit ‡πÄ‡∏£‡∏¥‡πà‡∏°


if question:
    with st.spinner("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
        # Step 1: ‡πÉ‡∏ä‡πâ Agent ‡∏´‡∏≤ IDs
        agent_result = agent_executor.invoke({"input": question})
        ids = agent_result.get("output", "").split(",")

        st.write("agent_result"+agent_result["output"])

        if ids and ids[0].strip():
            # Step 2: ‡∏î‡∏∂‡∏á Document ‡∏à‡∏≤‡∏Å ID ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
            retriever = vectorstore_name.as_retriever(search_kwargs={"k": 5})
            docs = retriever.get_relevant_documents(question)

            filtered_docs = [doc for doc in docs if str(doc.metadata.get("id")) in ids]

            if not filtered_docs:
                st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö ID")
            else:
                # Step 3: ‡πÉ‡∏ä‡πâ RAG ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡∏∏‡∏õ
                qa = RetrievalQA.from_chain_type(
                    llm=llm,
                    retriever=retriever,
                    chain_type="stuff",
                    chain_type_kwargs={"prompt": custom_prompt},
                    return_source_documents=True,
                )
                result = qa.invoke({"query": question})

                st.subheader("üìù ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:")
                st.write(result["result"])

                st.divider()
                st.subheader("üìö ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡∏°‡∏≤‡∏ï‡∏≠‡∏ö:")
                for doc in filtered_docs:
                    st.write(doc.page_content)
                    if doc.metadata.get("thumbnail"):
                        st.image(doc.metadata["thumbnail"], width=150)
        else:
            st.warning("‚ùó ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
