import os
import streamlit as st
from dotenv import load_dotenv

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_core.tools import tool
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from pinecone import Pinecone
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate, SystemMessagePromptTemplate


# ‡πÇ‡∏´‡∏•‡∏î ENV
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
INDEX_NAME = os.getenv("PINECONE_INDEX")

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Pinecone
pc = Pinecone(api_key=PINECONE_API_KEY)

index_names = {
    "name_th": "antiquities-name-th-index",
    "material_tags": "antiquities-material-tags-index",
    "artistic_description_th": "antiquities-artistic-description-th-index",
    "place_tags": "antiquities-place-tags-index",
    "historical_description_th": "antiquities-description-th-index"
}

# ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞ index
index_name = pc.Index(index_names["name_th"])
index_material = pc.Index(index_names["material_tags"])
index_artistic = pc.Index(index_names["artistic_description_th"])
index_place = pc.Index(index_names["place_tags"])
index_history = pc.Index(index_names["historical_description_th"])

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Embeddings ‡πÅ‡∏•‡∏∞ LLM
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
llm = ChatOpenAI(model="gpt-4o")

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° VectorStores
vectorstore_name = PineconeVectorStore(index=index_name, embedding=embeddings, namespace="name_namespace")
vectorstore_material = PineconeVectorStore(index=index_material, embedding=embeddings, namespace="material_namespace")
vectorstore_artistic = PineconeVectorStore(index=index_artistic, embedding=embeddings, namespace="artistic_namespace")
vectorstore_place = PineconeVectorStore(index=index_place, embedding=embeddings, namespace="place_namespace")
vectorstore_history = PineconeVectorStore(index=index_history, embedding=embeddings, namespace="history_namespace")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Tools
@tool
def search_by_name(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ (name_th) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_name.as_retriever(search_kwargs={"k": 3})
    docs = retriever.get_relevant_documents(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

@tool
def search_by_material(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏™‡∏î‡∏∏ (material_tags) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_material.as_retriever(search_kwargs={"k": 3})
    docs = retriever.get_relevant_documents(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

@tool
def search_by_artistic_description(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏®‡∏¥‡∏•‡∏õ‡∏∞ (artistic_description_th) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_artistic.as_retriever(search_kwargs={"k": 3})
    docs = retriever.get_relevant_documents(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

@tool
def search_by_place_tags(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏•‡∏¥‡∏ï (place_tags) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_place.as_retriever(search_kwargs={"k": 3})
    docs = retriever.get_relevant_documents(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

@tool
def search_by_description(query: str) -> str:
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (historical_background_description_th) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô ID ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤"""
    retriever = vectorstore_history.as_retriever(search_kwargs={"k": 3})
    docs = retriever.get_relevant_documents(query)
    return ",".join(doc.metadata.get("id", "") for doc in docs)

tools = [
    search_by_name,
    search_by_material,
    search_by_artistic_description,
    search_by_place_tags,
    search_by_description
]

# Prompt Template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡∏∏‡∏õ
agent_prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(
        "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    ),
    HumanMessagePromptTemplate.from_template("{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])


# ‡∏™‡∏£‡πâ‡∏≤‡∏á Agent ‡∏û‡∏£‡πâ‡∏≠‡∏° Prompt
agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# Streamlit ‡πÄ‡∏£‡∏¥‡πà‡∏°
st.set_page_config(page_title="Museum Chatbot", page_icon="üè∫")
st.title("Museum Siam - RAG + Agent")

question = st.text_input("üì• ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:")

if question:
    with st.spinner("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
        # Step 1: ‡πÉ‡∏ä‡πâ Agent ‡∏´‡∏≤ IDs
        agent_result = agent_executor.invoke({"input": question})
        ids = agent_result.get("output", "").split(",")

        st.write("agent_result"+agent_result["output"])

        # if ids and ids[0].strip():
        #     # Step 2: ‡∏î‡∏∂‡∏á Document ‡∏à‡∏≤‡∏Å ID ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
        #     retriever = vectorstore_name.as_retriever(search_kwargs={"k": 5})
        #     docs = retriever.get_relevant_documents(question)

        #     filtered_docs = [doc for doc in docs if str(doc.metadata.get("id")) in ids]

        #     if not filtered_docs:
        #         st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö ID")
        #     else:
        #         # Step 3: ‡πÉ‡∏ä‡πâ RAG ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡∏∏‡∏õ
        #         qa = RetrievalQA.from_chain_type(
        #             llm=llm,
        #             retriever=retriever,
        #             chain_type="stuff",
        #             chain_type_kwargs={"prompt": custom_prompt},
        #             return_source_documents=True,
        #         )
        #         result = qa.invoke({"query": question})

        #         st.subheader("üìù ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:")
        #         st.write(result["result"])

        #         st.divider()
        #         st.subheader("üìö ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡∏°‡∏≤‡∏ï‡∏≠‡∏ö:")
        #         for doc in filtered_docs:
        #             st.write(doc.page_content)
        #             if doc.metadata.get("thumbnail"):
        #                 st.image(doc.metadata["thumbnail"], width=150)
        # else:
        #     st.warning("‚ùó ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
