import streamlit as st
import os
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain_core.documents import Document
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQAWithSourcesChain

# ‡πÇ‡∏´‡∏•‡∏î .env
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
INDEX_NAME = os.getenv("PINECONE_INDEX")

llm = ChatOpenAI(model_name="gpt-4")


# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Pinecone
pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(INDEX_NAME)

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° embeddings
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

stats = index.describe_index_stats()
if stats.total_vector_count == 0:
    df = pd.read_csv("antiquities.csv")

    df = df[df["deleted_at"].isnull()]
    df["thumbnail"] = df["thumbnail"].fillna("")
    df["id"] = df["id"].fillna("").astype(str)

    docs = [
        Document(
            page_content = (
                f"‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì: {row['name_th']} ({row['name_en']}). "
                f"‡∏ó‡∏≥‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏™‡∏î‡∏∏: {row['material_tags']}. "
                f"‡∏¢‡∏∏‡∏Ñ‡∏™‡∏°‡∏±‡∏¢: {row['period_tags']}. "
                f"‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö: {row['place_tags']}."
                f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {row['artistic_description_th']}."
                f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {row['artistic_description_en']}."
                f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {row['historical_background_description_th']}."
                f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {row['historical_background_description_en']}."
                

            )
        )
        for _, row in df.iterrows()
    ]
    print("üü° Uploading documents to Pinecone...")
    PineconeVectorStore.from_documents(docs, embeddings, index_name=INDEX_NAME)
else:
    print(f"‚úÖ Already have {stats.total_vector_count} vectors in Pinecone.")






# ‡∏™‡∏£‡πâ‡∏≤‡∏á vectorstore
vectorstore = PineconeVectorStore(index=index, embedding=embeddings, text_key="text")

# === Streamlit UI ===
st.set_page_config(page_title="Museum Chatbot", page_icon="üè∫")
st.title("üóø ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì")

question = st.text_input("üì• ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:")


custom_prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""\
‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏ö‡∏£‡∏≤‡∏ì
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ:
{context}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
{question}

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"""
)

if question:
    with st.spinner("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å Pinecone..."):
        retriever = vectorstore.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
            "score_threshold": 0.50,
            "k": 2
             }
        )
        results = retriever.get_relevant_documents(question)
        #qa = RetrievalQA.from_chain_type(llm=llm,retriever=retriever,return_source_documents=True)       
        qa = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=retriever,
            chain_type="stuff",
            chain_type_kwargs={"prompt": custom_prompt},
            return_source_documents=True,
        )
        result=qa.invoke({"query":question})

   
        if results:
            for i, doc in enumerate(results, start=1):
                st.markdown(f"### ‚úÖ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà {i}")
                st.write(doc.page_content)

                if doc.metadata.get("thumbnail"):
                    st.image(doc.metadata["thumbnail"], width=200)

                st.caption(f"üÜî ID: {doc.metadata.get('id')}")

            st.subheader("üìù ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏£‡∏∏‡∏õ:")
            st.write(result["result"])

            st.divider()
            st.subheader("üìö ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡∏°‡∏≤‡∏ï‡∏≠‡∏ö:")
            for i, doc in enumerate(result["source_documents"], start=1):
                st.markdown(f"### ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà {i}")
                st.write(doc.page_content)